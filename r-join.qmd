---
execute:
  message: false
  error: true
---

# Verbs in depth: Matchmaking with joins {#r-verb-join}

Congratulations! This is the last key verb that you need to understand to address most stories.

::: {.alert .alert-secondary}
::: {.alert-heading .font-weight-bolder .fs-3}
In this chapter
:::

-   A `join` combines two or more tables (data frames) by column
-   joining to data frames requires exact matches on one or more columns. Close matches don't count.
-   Use codes in one data frame to "look up" information in another, and attach it to a row, such as the translation of codes to words or demographics of a Census tract.
-   Many public records databases come with "lookup tables" or "code sheets". Make sure to ask for the codes AND their translations in a data request.
-   Reporters don't always stick to matchmaking the way the database designers intended. "Enterprise" joins are those that let you find needles in a haystack, such as bus drivers with a history of DUIs.
-   Matching one data frame against an entirely different one will always produce mistakes, even if your code runs perfectly. You can minimize the *kind* of error you fear most -- false positives or false negatives -- but you likely will have to report out your findings on the ground.
:::

## Join basics and relational databases

Here is a great explainer on joins made by a previous MAIJ student, Andy Blye. Be sure to watch it:

{{< video https://youtu.be/4xPrnDYZXw4 width="400" height="300" >}}

\`joining" in computer programming match columns in one table [^r-join-1] to another. This is a fundamental way of designing data in both traditional database design and in the tidyverse, where each unit (person, ticket, vehicle) is stored in a different table. Reporters use it in many ways, some intended by the people who made the data source, and some not.

[^r-join-1]: We can use "table" and "data frame" interchangeably

Many databases are created expecting you to join tables because it's a more efficient way to store and work with large databases. This is what's called a "relational database", and they're everywhere (or at least everywhere that has updated its computer systems since 1980 or so). When storage space was expensive, it reduced the size of files because some important information is kept only once, even when it applies to millions of rows. Just as importantly, it means that someone doesn't have to change information in many places -- changing it once applies it to those millions of rows instantly. These are called "[relational databases](https://enou.co/blog/advantages-of-relational-database/)".

Here's an example, using campaign finance information. The Federal Elections Commission distributions campaign contribution in *related* tables, each referring to a different noun. One table lists donations, the other lists candidates and other political action committees.

![Campaign finance join](assets/images/r-verb-join-diagram.png){width="100%"}

One reason to do this is that you never have to worry that any changes to the candidate information -- the treasurer, the address or the office sought -- carries over to the donation. It's only listed once in the candidate table. Most large databases are constructed this way. For example:

-   Your school records are held using your student ID, which means that your address and home email only needs to be changed once, not in every class or in every account you have with the school.
-   Inspection records, such as those for restaurants, hospitals, housing code violations and workplace safety, typically have at least *three* tables: The establishment (like a restaurant or a workplace), an inspection (an event on a date), and a violation (something that they found). They're linked together using establishment ID's.
-   A court database usually has many types of records: A master case record links to information on charges, defendants, lawyers, sentences and court hearings.

Each table, then, is described using a different noun -- candidates or contributions; defendants or cases; students or courses. This conforms to the **tidy data** principle that different types of information are stored in different tables.

### join syntax

::: callout-warning
There was a huge change in the join verb and its arguments in early 2023. If you have not updated your tidyverse package in a while this may not work. There are actually pretty good explanations of the [concept of joining](https://dtplyr.tidyverse.org/reference/left_join.dtplyr_step.html) and the [variations of it in R](https://dplyr.tidyverse.org/reference/join_by.html) in the documentation.
:::

There are several kinds of joins, but the syntax is similar across them.

      old_table |>
         inner_join (new_table , join_by = (name of old_table column = name of new_table column) )
         

## Matchmaking with joins

The type of join described above is often referred to as a "lookup table". You'll match codes to their meanings in a way that was intended by the people who made the database. But there are other ways reporters use joins:

### "Enterprise" joins {.unnumbered}

Journalists have taken to calling a specific kind of join "enterprise", referring to the enterprising reporters who do this. Here, you'll look for needles in a haystack. Some of the most famous data journalism investigations relied on joining two databases that started from completely different sources, such as:

-   Bus drivers who had DUI citations
-   Donors to a governor who got contracts from the state
-   Day care workers with criminal records

When you match these kinds of datasets, you will always a mistake --- some apparent matches are incorrect in the real world; some matches that should exist don't because of variations in names or other details. You always have to report out any suspected matches, so they are time consuming stories.

In the mid-2000s, when some politicians insisted that dead people were voting and proposed measures to restrict registration, almost every regional news organization sent reporters on futile hunts for the dead voters. They got lists of people on the voter rolls, then lists of people who had died through the Social Security Death Index or local death certificates. I never met anyone who found a single actual dead voter, but months of reporter-hours were spent tracking down each lead.

It's very common for two people to have the same name in a city. In fact, it's common to have two people at the same home with the same name -- they've just left off "Jr." and "Sr." in the database. In this case, you'll find matches that you shouldn't. These are false positives, or Type I errors in statistics.

Also, we rarely get dates of birth or Social Security Numbers in public records, so we have to join by name and sometimes location. If someone has moved, sometimes uses a nickname, or the government has recorded the spelling incorrectly, the join will fail -- you'll miss some of the possible matches. This is very common with company names, which can change with mergers and other changes in management, and can be listed in many different ways.

These are false negatives, or Type II errors in statistics.[^r-join-2]

[^r-join-2]: I remember them by thinking of the boy who cried wolf. When the village came running and there was no wolf, it was a Type I error, or false positive ; when the village ignored the boy and there was a wolf, it was a Type II error, or false negative.

In different contexts, you'll want to minimize different kinds of errors. For example, if you are looking for something extremely rare, and you want to examine every possible case -- like a child sex offender working in a day care center -- you might choose to make a "loose" match and get lots of false positives, which you can check. If you want to limit your reporting only to the most promising leads, you'll be willing to live with missing some cases in order to be more sure of the joins you find.

You'll see stories of this kind write around the lack of precision -- they'll often say, "we verified x cases of...." rather than pretend that they know of them all.

### Find cases with interesting characteristics {.unnumbered}

You'll often want to learn more about a geographic area's demographics or voting habits or other characteristics, and match it to other data. Sometimes it's simple: Find the demographics of counties that switched from Trump to Biden as a way to isolate places you might want to visit. Another example from voting might be to find the precinct that has the highest percentage of Latino citizens in the county, then match that precinct against the voter registration rolls to get a list of people you might want to interview on election day. In these instances, the `join` is used for a `filter`.

This is also common when you have data by zip code or some other geography, and you want to find clusters of interesting potential stories, such as PPP loans in minority neighborhoods.

### Summarize data against another dataset {.unnumbered}

The previous examples all result in lists of potential story people or places. If you use join on summarized data, you can characterize a broad range of activity across new columns. Simplified, this is how you can write that more PPP money went to predominantly white neighborhoods than those that were majority Black.

## Simple lookup join using PPP industry codes

```{r}
#| label: setup
#| include: false

library(tidyverse)
library(lubridate)

```

The PPP data has a code called the `naics_code`, which is a standardized code to identify industries. They are assigned by the company itself or by the bank, not by the government, but they are a good guide. We'll use a data frame that contains the list of industries and match it to the PPP data. (The lookup table was derived from the `concordance` package in R, but is fully explained at the [Census website](https://www.census.gov/naics/?58967?yearbck=2017).)

::: {.alert .alert-success .alert-dothis}
Once you load these data frames, be sure to explore them a little to make sure you understand what they contain.
:::

```{r}
#| label: loadppp

naics_codes <- readRDS( url ( "https://cronkitedata.s3.amazonaws.com/rdata/naics_lookup.RDS"))
ppp_orig <- readRDS (url ( "https://cronkitedata.s3.amazonaws.com/rdata/ppp_az_loans.RDS"))

glimpse(naics_codes)
```

Here is a simple example of filtering for the sector that begins with "72", then getting information about the loans to industries within that sector:

```{r}
#| label: pick_sector

ppp_sector72 <- 
  ppp_orig |> 
  filter ( str_like ( naics_code, "72%"))


```

To put this together with industry descriptions, you "join" it using the column that it has in common -- the `naics_code`. This is an example of an "inner join", in which only the rows that match are kept in the result. The result below uses just a few columns from the saved data frame, and then picks out some random rows to view:

```{r}
#| label: joinindustry

loans_with_industry <- 
  ppp_sector72 |>
  inner_join ( naics_codes, join_by = naics_code)  
```

(In this case, they have the same column name, but they don't have to. As long as they CONTAIN the same thing, they can have different names. You can also join using more than one column, such as county and state together.)

```{r print-loans, echo=FALSE}
loans_with_industry |>
  select (Borrower =  borrower_name, city = borrower_city, naics_code, sector_desc, subsector_desc, naics_desc, amount) |> 
  sample_n ( 100 ) 
```

Think about what this means: You now have another thing for grouping, so you can see, for instance, how much went to restaurants, or which restaurants on your block got loans.

## Joining risks

### joining tl;dr

There are lots of risks in joining tables that you created yourself, or that were created outside a big relational database system. Keep an eye on the number of rows returned every time that you join -- you should know what to expect.

### Double counting with joins

We won't go into this in depth, but just be aware it's easy to double-count rows when you join. Here's a made-up example, in which a zip code is on the border and is in two counties:

Say you want to use some data on zip codes :

| zip code | county   | info           |
|----------|----------|----------------|
| 85232    | Maricopa | some data      |
| 85232    | Pinal    | some more data |

and match it to a list of restaurants in a zip code:

| zip code | restaurant name               |
|----------|-------------------------------|
| 85232    | My favorite restaurant        |
| 85232    | My second-favorite restaurant |

When you match these, you'll get **4** rows:

| zip code | county   | info           | restaurant name               |
|----------|----------|----------------|-------------------------------|
| 85232    | Maricopa | some data      | My favorite restaurant        |
| 85232    | Pinal    | some more data | My favorite restaurant        |
| 85232    | Maricopa | some data      | My second-favorite restaurant |
| 85232    | Pinal    | some more data | My second-favority restaurant |

Now, every time you try to count restaurants, these two will be double-counted.

In computing, this is called a "many-to-many" relationship -- there are many rows of zip codes and many rows of restaurants. In journalism, we call it spaghetti. It's usually an unintended mess.

### Losing rows with joins

The opposite can occur if you aren't careful and there are items you want to keep that are missing in your reference table. That's what happened in the immunization data above for the seven schools that I couldn't find.

## Resources

-   The "[Relational data](https://r4ds.had.co.nz/relational-data.html)" chapter in the R for Data Science textbook has details on exactly how a complex data set might fit together.

-   [An example using a superheroes dataset](https://stat545.com/join-cheatsheet.html#left_joinsuperheroes-publishers), from Stat 545 at the University of British Columbia
