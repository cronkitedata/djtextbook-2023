# Verbs in depth: Aggregating with groups {#r-verb-groupby}


```{r setup, include=FALSE, message=FALSE}

library(tidyverse)
library(lubridate)
library(janitor)


```





::: {.alert .alert-secondary}
::: {.alert-heading .font-weight-bolder .fs-3}
In this chapter: 
::: 

* `group_by` and `summarize` are the tidyverse's version of Excel pivot tables, with many more possibilities.
* R is picky and will create different rows for the tiniest difference between values, such as "Lettuce" vs. "lettuce". 
* You will rarely use `group_by` without `summarize`. 
* You will often have to accommodate missing data, or the dreaded "NA" values.
* Go from "long" database format to "wide" spreadsheet format and back using `pivot_` functions.

::: 


This chapter continues with the Paycheck Protection Program, or PPP, loans in Arizona.   Full documentation of the dataset is in the [Appendix](appendix-ppp.html). If you haven't already, look through that documentation before you start. 

::: {.alert-success .alert-dothis}

As you have in the last several chapters, open your R project and create a new Quarto document with the [front matter and libraries](https://gist.github.com/sarahcnyt/e60ad2d7ccf65498fc88791f3bb683ae). 

Then load the saved PPP data with this code chunk: 

::: 




```{r}
#| label: read-orig
#| echo: true
#| eval: true

ppp_orig <- readRDS (
               url ( 
                 "https://cronkitedata.s3.amazonaws.com/rdata/ppp_az_loans.RDS"
                 )
               )




```



## `summarize` 

`summarize`^[A synonym for the British spelling `summarise`, which you'll see in a lot of examples]  computes summary statistics such as the number of rows in a dataset, or the sum and average of dollar values. It creates a new data frame with just the summary statistics and none of the columns from the original data frame. Using it alone produces a data frame with one row. It's the equivalent of putting nothing in your pivot table in Excel other than the "Values" area. 
 
### The dreaded NA 

You saw in the `mutate` section that missing values are always a problem. Because they're unknown, they can't match anything else, they can't be considered 0, and they can warp any answers you get. But there's usually nothing you can do about missing data, so you have to tell the program exactly what to do about them. There are two choices: 

* Let them infect everything they touch, turning everything into `NA`. In this scenario, a total of the dollar values in a column would be NA if **any** of the values in that column is missing. 
* Ignore them in a computation completely, effectively removing that row from your calculation. 

There's no right answer, and it depends on what you're doing.  In some cases, you know that they stand for the value `0`, and in others you don't. We will usually ignore them by adding an *argument* to every summary function that could be infected by them : `na.rm = TRUE` , which means, "remove NA's before you do anything.". 


### Summary functions 

Some of the common functions you'll use to summarize are : 

* `mean (column_name, na.rm=T)` --  for an average
* `sum (column_name, na.rm = T)`
* `n()` -- for "how many", or "count". There is no NA argument because it is counting rows, not values.
* `median (column_name, na.rm=T)` 
* `min (column_name, na.rm=T)`
* `max (column_name , na.rm=T)`


Here is an example, creating some of the summary statistics that appeared in the `skimr` report: 


```{r}
#| label: summarize-all

ppp_orig %>%
  summarize ( n(), 
              mean (amount, na.rm=T), 
              mean (forgiveness_amount, na.rm=T), 
              min (date_approved, na.rm=T), 
              max (date_approved, na.rm= T)
  ) %>%
  glimpse()
              

```


This produced a data frame with 1 row and 5 columns. The column names are the same as the formulas that created them, which is difficult to work with. Create new column names using the name (in back-ticks if it's got spaces or special characters) and assign them the values of the summaries using the `=` sign:


```{r}
#| label: summary_stats_named

ppp_orig %>%
  summarize ( number_of_rows =  n(), 
              mean_amount = mean (amount, na.rm=T), 
              mean_forgiven = mean (forgiveness_amount, na.rm=T), 
              first_loan = min (date_approved, na.rm=T), 
              last_loan = max (date_approved, na.rm= T)
  ) %>%
  glimpse()
              

```


## Grouping 

Now that you know how to summarize the whole data frame, you'll want to start getting totals by category. This is the same thing as a pivot table -- the columns you use as "groups" are the equivalent of the Rows area in Excel: 


![](assets/images/r-verb-group-pivotcompare.png){width=100%}

### Grouping by one column

In the PPP data, the "draw" refers to which of the two programs was involved - the original one, or the one passed by Congress in late 2020. 

Here's how we'd get some key statistics by draw: 


```{r} 
#| label: group-draw

ppp_orig %>%
  group_by ( draw ) %>%
  summarize ( first_loan = min ( date_approved ), 
              total_amount = sum (amount), 
              total_forgiven = sum (forgiveness_amount, na.rm=T), 
              `# of loans` = n() 
  )


```


This code chunk expresses the amounts in millions of dollars, making it a little easier to read. There is no `na.rm=T` for the `date_approved` and the `amount` columns because they're always filled in. It also computes the percent of total loan amount that has been forgiven --- or paid by taxpayers rather than the borrowers.


```{r}
#| label: millions 
#| results : hide


ppp_orig %>%
  group_by ( draw ) %>%
  summarize ( first_loan = min ( date_approved ), 
              amount_million = sum (amount/1000000), 
              forgiven_million = sum (forgiveness_amount/1000000, na.rm=T), 
              `# of loans` = n() ,
              pct_amt_forgiven = forgiven_million / amount_million * 100
  )


```

### Conditionally count rows

You can use the same conditions you learned in the `mutate` section to provide a screen for counting. The code to do it is a little counterintuitive, but it takes advantage of a simple behavior in R: Anything that is TRUE is  equal to the numeral 1. Anything that is FALSE is  equal to 0 (zero). So you can add up the results of a condition to get the number of rows that match your condition. 

```{r}
#| label: conditional-count
#| eval: false


ppp_orig |> 
  group_by (draw) |> 
  summarize ( all_loans = n(), 
              forgiven_loans = sum ( forgiveness_amount > 0, na.rm = T))


```

### Grouping by more than one column 

If you wanted to know the numbers outstanding and forgiven by draw, you could add another column to the group by: 


```{r}
#| label: twogroups

ppp_orig %>%
  group_by ( loan_status, draw ) %>%
  summarize ( first_loan = min ( date_approved ), 
              total_amount = sum (amount), 
              total_forgiven = sum (forgiveness_amount, na.rm=T), 
              `# of loans` = n() 
  )


```

The `summarize` verb here has created a data frame that has only the variables you identified in the `group_by` and `summarize` commands - everything else has been removed, since it's a *summary* of your data.


### Understanding grouped data 

You may have noticed an odd warning after you ran the last code chunk that said:  

```markdown
"`summarise()` has grouped output by 'loan_status'. You can override using the `.groups` argument." 
```

What does that mean? 

When you grouped by loan status and draw, R effectively split up your data frame into five independent and completely divorced piles - one for each combination of draw and status that it found. It processed them one by one to create the output data frame that was printed out. 

After it's done summarizing your data, R doesn't know what you want to do with the piles -- keep them, or put everything back together again.  

By default, after you group by more than one column, it maintains the separate piles for all but the last group in your list under `group_by` -- in this case the `loan_status`. Here, everything you do after this will work on three piles seperately.The message tells you what it did with the piles, and how to change that behavior.

That's often what you want, as you'll see in the next chapter. But if you want to stop it from doing that, then add an argument that looks like this at the end of the `summarize` statement:

```markdown
 summarize ( loan_count = n(), 
            .groups = "drop")

```

or add a line at the end of your code (after a pipe) to return it to normal: `ungroup()`. You can get some really strange answers if you save a data frame that's grouped and you don't notice it. 


Here's what a "glimpse()" looks like for a data frame that has retained some groups: 

```{r}
#| label: lk_groups 

ppp_orig %>% group_by ( loan_status) %>% glimpse()


```
Notice the "Groups" row at the top -- that tells you it's still got three piles. 


### Totals and percent of totals










## Converting to "wide" (spreadsheet) format


Normally, you'll only want to have one summary statistic shown in a rectangle, with one column spread across the top and another column shown in rows. In R, this is done by "pivoting" your tables. 

In this case, we're going from a "long" to a "wide" data structure, so it's called `pivot_wider`.  

Here's an explanation of what the command looks like. Don't try to run this:

```markdown

pivot_wider ( id_cols = *list of columns to keep down the side* , 
            names_from = *the name of the column supplying the headings across the top*, 
            values_from = *the values you want to show in each cell* , 
            values_fill = *what you want to show if it's empty, usually 0 *
            )
```


So here's how you'd do it for the previous example: 

```{r pivotwider, echo=TRUE, eval=knitr::is_html_output()}

ppp_orig %>%
  group_by ( loan_status, draw ) %>%
  summarize ( loan_count = n() ) %>%
  pivot_wider ( id_cols = loan_status, 
                names_from = draw, 
                values_from = loan_count, 
                values_fill = 0)
  



```


Your instinct will often be that you want to see your data in this form, but you can and should actually do most of your work without it, then turn it on its head when you want to display it.  This is usually your very last step. 



### Percentages 

You noticed that when you created the summaries, there was no option to create a "percent of total" such as the percent of loans in each draw, or the percent of money that had been forgiven. 

You'll get more on the `mutate` verb in the next chapter, but it's used to add a column to a data frame. You can use the same summary statistics you create in the `summarize` section, but they'll be added to the existing data frame.  Here's how you can try it first using just one "group_by" column:


```{r grp-pcts, echo=TRUE, eval=knitr::is_html_output()}


ppp_orig %>%
  group_by ( draw) %>%
  summarize ( loan_count = n() ) %>%
  mutate ( pct_of_total = loan_count / sum(loan_count) * 100)
  


```

When you add a second group_by, R keeps those columns and creates a percentage based on the subtotal: 

```{r grp-pctsub, echo=TRUE, eval=knitr::is_html_output()}


ppp_orig %>%
  group_by ( draw, loan_status) %>%
  summarize ( loan_count = n() ) %>%
  mutate ( pct_of_draw = loan_count / sum(loan_count) * 100)
  


```





## Practice

Putting together the grouping and summarizing, along with the commands you learned last chapter to `filter`, `arrange` and display the `head()` and `tail()` of a dataset should equip you to write the code for these questions: 


1. Which lenders provided the most loans? 
2. Which lenders provided the most amount of money loaned? 
3. Which borrowers got the least amount of money? 
4. Show the number of loans in each draw that went to the 24 (including `NA`) types of businesses. To see them all on one screen, add ", rows.print=25" to the heading of the code chunk like this: `{r  , rows.print=25}`
5. Try to compute the percent of loans that went to projects in each county in Arizona. This will require first filtering, then grouping. 





